{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86c6a43",
   "metadata": {},
   "source": [
    "# Seq2Seq\n",
    "Unlike the previous two notebooks, the material in this one (unless you've worked closely with NLP or the like) will likely be new to you. However, the main novelty can be summarized as follows: using RNNs in an encoder/decoder architecture.\n",
    "\n",
    "Encoder/decoders come up *all* the time in deep learning, so it's useful to become familiar with the concept now: there are differences in implementation details of what the encoder and decoder sides looks like, but fundamentally this design pattern is quite common. Let's load in the data.\n",
    "\n",
    "The data loading is more involved this time around, but we'll ignore the details for now. We will ultimately need to see how such work would translate to the AlphaFold case, but let's focus on the model for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d753eeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x12f283bd0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import unicodedata\n",
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "927e0036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10599 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4345\n",
      "eng 2803\n",
      "['je souffre encore a cause du decalage horaire .', 'i m still suffering from jet lag .']\n"
     ]
    }
   ],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "if not os.path.exists(\"data.zip\"):\n",
    "    url = \"https://download.pytorch.org/tutorial/data.zip\"\n",
    "    urllib.request.urlretrieve(url, \"data.zip\")\n",
    "\n",
    "with zipfile.ZipFile(\"data.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "    \n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long).view(-1, 1)\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)\n",
    "\n",
    "tensor_pairs = [tensorsFromPair(pair) for pair in pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b20121",
   "metadata": {},
   "source": [
    "The `Encoder` takes the data to a context, and the `Decoder` takes the corresponding context to a corresponding prediction of the word:\n",
    "\n",
    "![](https://pytorch.org/tutorials/_images/seq2seq.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb38fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        # x : N x T x D\n",
    "        N, T, D = x.shape\n",
    "        embedded = self.embedding(x).view(N, T, -1)\n",
    "        _, hn = self.gru(embedded, hidden)\n",
    "        return hn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7edd9ddc",
   "metadata": {},
   "source": [
    "Previously, we had the encoder simply taking in the input sentence, mappping that to a context vector, and directly being consumed by the decoder. However, there were two main issues with this. The first is simply that the context is *only* being fed in at the first step of the decoder. We hope that the hidden state of the decoder is retaining that context for future prediction, but it seems unlikely that long sequences will be capable of such retention. The second deficiency is that the context is fed in without any separation of *how* it is to be used per word prediction: the context is simply given, with the GRU expected to pry apart which parts are relevant per word.\n",
    "\n",
    "To amend these deficiencies, we add this \"attention\" mechanism, which remedies the second issue. For the first, we simply feed in the encoded vector *per* prediction. Note that the encoder is *exactly* the same as it was previously: it's just that we now feed it into the decoder at each step of the prediction.\n",
    "\n",
    "Recall the basic idea: we want to *attend* to the subsets of the encoded input that are relevant, with this \"attention\" vector just being a probability vector. The specific mechanism used to determine that weight will be some learned function of the previous word (since we expect the previous word to be relevant to where we should look) *and* also the hidden state (which conceptually contains a summary of all the previously encountered words). In other words, we believe the output sentence so far contains the relevant context of where we should pay attention in the input sentence. The use of the hidden state as opposed to the entire output sentence is likely just to reduce the number of parameters we need to learn and to better generalize, although this detail is not entirely clear to me.\n",
    "\n",
    "To summarize: the encoder remains as was whereas the decoder now maps the `[x, hidden] -> attn_weights`, which then multiplies the encoded vector to give the attended encoded vector. This attended encoded vector now serves the role that the embedded vector previously served, namely as the first input to the GRU. This may seem a bit odd (after all, why perhaps would it not replace the `hidden` argument to the GRU), but just reemember that the hidden state needs to be retained for the \"rolled context,\" and the first argument is supposed to be the specific point to use that context to predict. So, that's why the GRU's first argument now becomes the encoded context: it contains *exactly* the same information of `x` but in a more informative light. That is, instead of simply saying *what* the previous word was, it says what the relative context of thatword from the input was.\n",
    "\n",
    "That's it! Nothing else changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74883f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.attention = nn.Linear(2 * hidden_size, hidden_size)\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x, hidden, encoded_input):\n",
    "        N, T, D = x.shape\n",
    "        embedded = self.embedding(x).view(N, T, -1)[:, 0, :] # N x H\n",
    "        \n",
    "        attention_inputs = torch.hstack([embedded, hidden]) # N x 2H\n",
    "        attention = self.attention(attention_inputs) # N x T\n",
    "        attention_weights = torch.nn.Softmax(attention) # N x H\n",
    "        attended_input = torch.matmul() # (N x T x H)^T x (N x T x 1) -> (N x H x 1)\n",
    "        \n",
    "        output, hn = self.gru(embedded, hidden) # input[0]: [N x H x 1]\n",
    "        output = self.out(output.view(1, -1))\n",
    "        return output, hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c420fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.4702e-01,  4.1379e-01,  3.6360e-01,  6.2382e-02, -1.8443e-02,\n",
      "           2.7656e-01, -2.2305e-01,  3.3506e-01, -6.0423e-02, -5.3020e-01,\n",
      "          -1.1673e-01,  1.4360e-03, -4.9969e-01, -1.2383e-01,  3.8583e-02,\n",
      "           4.5550e-04,  2.7990e-01,  4.5993e-01,  3.0449e-01,  2.7023e-01,\n",
      "          -1.2698e-01, -2.5040e-01, -1.6139e-01, -5.4098e-01, -3.0216e-01,\n",
      "          -1.0756e-01,  1.3527e-02, -1.3165e-01, -1.8842e-03,  3.8053e-02,\n",
      "           2.4843e-02,  4.5525e-02,  2.6044e-01, -4.8941e-01, -5.0603e-02,\n",
      "          -7.3428e-01, -2.4093e-01,  2.3459e-01,  8.3031e-02, -7.1811e-02,\n",
      "           3.8970e-01,  2.3943e-01, -4.1332e-01, -5.9104e-02, -2.5092e-02,\n",
      "           2.5156e-01, -3.5193e-02,  3.2591e-01,  7.0028e-02,  2.9215e-01,\n",
      "          -3.4554e-01,  2.7159e-01,  8.5373e-02, -2.6173e-02,  7.2862e-02,\n",
      "           8.1261e-02, -1.1153e-01, -3.4511e-01,  2.2750e-02,  5.2740e-02,\n",
      "          -2.0742e-01, -1.5062e-01, -3.6496e-01,  7.8150e-02,  1.1871e-01,\n",
      "           1.9632e-01, -6.2270e-01, -6.3603e-02, -7.3362e-02, -4.5290e-01,\n",
      "          -6.5393e-02,  1.9670e-01,  5.8226e-01, -7.2621e-02, -1.5521e-02,\n",
      "           6.6045e-02, -2.7354e-01, -1.7995e-01, -1.2984e-01, -3.1109e-01,\n",
      "           6.5767e-02, -4.6612e-01,  5.1139e-01,  1.4910e-01, -7.5060e-02,\n",
      "          -3.9137e-01,  3.9427e-01, -1.0093e-01, -1.9325e-01, -4.0388e-02,\n",
      "          -2.5375e-02, -4.3807e-01, -3.5262e-01,  7.2008e-02, -9.5806e-02,\n",
      "           2.2397e-01, -4.1512e-02, -9.4169e-04, -3.2766e-01, -2.8407e-01,\n",
      "          -6.7399e-01,  1.6756e-01,  1.5786e-01,  1.4902e-01, -2.8709e-02,\n",
      "           2.0613e-01, -2.7328e-01, -1.7146e-01, -1.2982e-01,  9.1051e-02,\n",
      "          -1.3765e-01,  1.8967e-01,  3.9059e-01, -1.3429e-01, -4.6178e-01,\n",
      "          -3.0819e-01, -1.2739e-01,  1.9111e-01, -2.3760e-01, -3.2454e-02,\n",
      "           1.3315e-01,  1.1180e-01,  2.9457e-01, -2.1291e-01, -3.1088e-01,\n",
      "           5.3021e-02, -3.1816e-01,  1.0788e-01]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "N = 1\n",
    "H = 128\n",
    "\n",
    "encoder = Encoder(input_lang.n_words, H)\n",
    "decoder = Decoder(output_lang.n_words, H)\n",
    "\n",
    "input_tensor = torch.stack([tensor_pairs[k][0] for k in range(10, 10 + N)])\n",
    "init_hidden = torch.zeros((1, N, H))\n",
    "\n",
    "encoded = encoder(input_tensor, init_hidden)\n",
    "\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89f2ad88",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1\n",
    "H = 128\n",
    "\n",
    "encoder = Encoder(input_lang.n_words, H)\n",
    "decoder = Decoder(output_lang.n_words, H)\n",
    "\n",
    "input_tensor = torch.stack([tensor_pairs[k][0] for k in range(10, 10 + N)])\n",
    "output_tensor = torch.stack([tensor_pairs[k][0] for k in range(10, 10 + N)])\n",
    "init_hidden = torch.zeros((1, N, H))\n",
    "\n",
    "encoded = encoder(input_tensor, init_hidden)\n",
    "decoded, decoded_hn = decoder(output_tensor[:,0:1,:], encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74f2598e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4j/yb1phr856mgf1c7fysrq3_6c0000gs/T/ipykernel_14308/406562231.py:44: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
      "  prev_word = torch.tensor(np.array([[[prev_word_value]]]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0/200 -- Loss : 7426.76171875\n",
      "Epoch : 1/200 -- Loss : 4514.91650390625\n",
      "Epoch : 2/200 -- Loss : 7893.115234375\n",
      "Epoch : 3/200 -- Loss : 21240.619140625\n",
      "Epoch : 4/200 -- Loss : 10673.193359375\n",
      "Epoch : 5/200 -- Loss : 22060.134765625\n",
      "Epoch : 6/200 -- Loss : 23320.015625\n",
      "Epoch : 7/200 -- Loss : 26930.8359375\n",
      "Epoch : 8/200 -- Loss : 29868.751953125\n",
      "Epoch : 9/200 -- Loss : 21693.046875\n",
      "Epoch : 10/200 -- Loss : 25108.3515625\n",
      "Epoch : 11/200 -- Loss : 32041.6015625\n",
      "Epoch : 12/200 -- Loss : 39277.30078125\n",
      "Epoch : 13/200 -- Loss : 28910.357421875\n",
      "Epoch : 14/200 -- Loss : 21706.818359375\n",
      "Epoch : 15/200 -- Loss : 16961.5859375\n",
      "Epoch : 16/200 -- Loss : 19543.375\n",
      "Epoch : 17/200 -- Loss : 22329.923828125\n",
      "Epoch : 18/200 -- Loss : 24182.126953125\n",
      "Epoch : 19/200 -- Loss : 20962.53515625\n",
      "Epoch : 20/200 -- Loss : 21785.48046875\n",
      "Epoch : 21/200 -- Loss : 13536.11328125\n",
      "Epoch : 22/200 -- Loss : 16217.443359375\n",
      "Epoch : 23/200 -- Loss : 13043.6455078125\n",
      "Epoch : 24/200 -- Loss : 11083.033203125\n",
      "Epoch : 25/200 -- Loss : 8489.736328125\n",
      "Epoch : 26/200 -- Loss : 8124.513671875\n",
      "Epoch : 27/200 -- Loss : 7668.37255859375\n",
      "Epoch : 28/200 -- Loss : 8880.4638671875\n",
      "Epoch : 29/200 -- Loss : 6432.490234375\n",
      "Epoch : 30/200 -- Loss : 6533.1650390625\n",
      "Epoch : 31/200 -- Loss : 8256.986328125\n",
      "Epoch : 32/200 -- Loss : 5960.390625\n",
      "Epoch : 33/200 -- Loss : 6339.62060546875\n",
      "Epoch : 34/200 -- Loss : 7332.2607421875\n",
      "Epoch : 35/200 -- Loss : 8989.12109375\n",
      "Epoch : 36/200 -- Loss : 5848.21533203125\n",
      "Epoch : 37/200 -- Loss : 6902.86767578125\n",
      "Epoch : 38/200 -- Loss : 7844.42529296875\n",
      "Epoch : 39/200 -- Loss : 7587.61181640625\n",
      "Epoch : 40/200 -- Loss : 7302.10546875\n",
      "Epoch : 41/200 -- Loss : 5954.22998046875\n",
      "Epoch : 42/200 -- Loss : 5989.150390625\n",
      "Epoch : 43/200 -- Loss : 5819.9462890625\n",
      "Epoch : 44/200 -- Loss : 6436.103515625\n",
      "Epoch : 45/200 -- Loss : 5797.33447265625\n",
      "Epoch : 46/200 -- Loss : 4929.55908203125\n",
      "Epoch : 47/200 -- Loss : 5835.13916015625\n",
      "Epoch : 48/200 -- Loss : 9012.3134765625\n",
      "Epoch : 49/200 -- Loss : 7653.10791015625\n",
      "Epoch : 50/200 -- Loss : 5541.64111328125\n",
      "Epoch : 51/200 -- Loss : 5353.32763671875\n",
      "Epoch : 52/200 -- Loss : 4524.8828125\n",
      "Epoch : 53/200 -- Loss : 4585.41455078125\n",
      "Epoch : 54/200 -- Loss : 5360.37255859375\n",
      "Epoch : 55/200 -- Loss : 9250.6572265625\n",
      "Epoch : 56/200 -- Loss : 6122.86474609375\n",
      "Epoch : 57/200 -- Loss : 6294.1572265625\n",
      "Epoch : 58/200 -- Loss : 5642.1376953125\n",
      "Epoch : 59/200 -- Loss : 4754.50341796875\n",
      "Epoch : 60/200 -- Loss : 5777.0849609375\n",
      "Epoch : 61/200 -- Loss : 6568.62353515625\n",
      "Epoch : 62/200 -- Loss : 6596.86962890625\n",
      "Epoch : 63/200 -- Loss : 5739.26953125\n",
      "Epoch : 64/200 -- Loss : 5760.103515625\n",
      "Epoch : 65/200 -- Loss : 4262.5537109375\n",
      "Epoch : 66/200 -- Loss : 5855.69921875\n",
      "Epoch : 67/200 -- Loss : 9117.5048828125\n",
      "Epoch : 68/200 -- Loss : 5733.54052734375\n",
      "Epoch : 69/200 -- Loss : 4850.8515625\n",
      "Epoch : 70/200 -- Loss : 3910.677001953125\n",
      "Epoch : 71/200 -- Loss : 5253.48681640625\n",
      "Epoch : 72/200 -- Loss : 5931.47021484375\n",
      "Epoch : 73/200 -- Loss : 5294.80126953125\n",
      "Epoch : 74/200 -- Loss : 4507.5830078125\n",
      "Epoch : 75/200 -- Loss : 4331.0029296875\n",
      "Epoch : 76/200 -- Loss : 5827.96240234375\n",
      "Epoch : 77/200 -- Loss : 5999.71435546875\n",
      "Epoch : 78/200 -- Loss : 6121.23291015625\n",
      "Epoch : 79/200 -- Loss : 4620.7158203125\n",
      "Epoch : 80/200 -- Loss : 4027.93017578125\n",
      "Epoch : 81/200 -- Loss : 5743.80126953125\n",
      "Epoch : 82/200 -- Loss : 6179.1318359375\n",
      "Epoch : 83/200 -- Loss : 4463.767578125\n",
      "Epoch : 84/200 -- Loss : 5205.13134765625\n",
      "Epoch : 85/200 -- Loss : 6113.77978515625\n",
      "Epoch : 86/200 -- Loss : 5637.169921875\n",
      "Epoch : 87/200 -- Loss : 4093.860595703125\n",
      "Epoch : 88/200 -- Loss : 3895.666259765625\n",
      "Epoch : 89/200 -- Loss : 5195.77197265625\n",
      "Epoch : 90/200 -- Loss : 5467.576171875\n",
      "Epoch : 91/200 -- Loss : 5310.59619140625\n",
      "Epoch : 92/200 -- Loss : 4476.55712890625\n",
      "Epoch : 93/200 -- Loss : 6650.99462890625\n",
      "Epoch : 94/200 -- Loss : 5662.77978515625\n",
      "Epoch : 95/200 -- Loss : 4098.1875\n",
      "Epoch : 96/200 -- Loss : 3452.294921875\n",
      "Epoch : 97/200 -- Loss : 5099.8037109375\n",
      "Epoch : 98/200 -- Loss : 4469.86181640625\n",
      "Epoch : 99/200 -- Loss : 3885.395263671875\n",
      "Epoch : 100/200 -- Loss : 4139.447265625\n",
      "Epoch : 101/200 -- Loss : 6647.4296875\n",
      "Epoch : 102/200 -- Loss : 5727.0478515625\n",
      "Epoch : 103/200 -- Loss : 4454.49755859375\n",
      "Epoch : 104/200 -- Loss : 4948.259765625\n",
      "Epoch : 105/200 -- Loss : 3474.16064453125\n",
      "Epoch : 106/200 -- Loss : 4206.0224609375\n",
      "Epoch : 107/200 -- Loss : 7202.68603515625\n",
      "Epoch : 108/200 -- Loss : 5229.42724609375\n",
      "Epoch : 109/200 -- Loss : 4089.64453125\n",
      "Epoch : 110/200 -- Loss : 4143.130859375\n",
      "Epoch : 111/200 -- Loss : 6688.2880859375\n",
      "Epoch : 112/200 -- Loss : 5618.18359375\n",
      "Epoch : 113/200 -- Loss : 4177.01806640625\n",
      "Epoch : 114/200 -- Loss : 4965.47265625\n",
      "Epoch : 115/200 -- Loss : 4041.228515625\n",
      "Epoch : 116/200 -- Loss : 4213.0888671875\n",
      "Epoch : 117/200 -- Loss : 4845.66162109375\n",
      "Epoch : 118/200 -- Loss : 7292.615234375\n",
      "Epoch : 119/200 -- Loss : 4992.05224609375\n",
      "Epoch : 120/200 -- Loss : 4240.96044921875\n",
      "Epoch : 121/200 -- Loss : 4599.2138671875\n",
      "Epoch : 122/200 -- Loss : 4618.705078125\n",
      "Epoch : 123/200 -- Loss : 4251.451171875\n",
      "Epoch : 124/200 -- Loss : 5180.49658203125\n",
      "Epoch : 125/200 -- Loss : 4771.85693359375\n",
      "Epoch : 126/200 -- Loss : 5803.69140625\n",
      "Epoch : 127/200 -- Loss : 8577.6875\n",
      "Epoch : 128/200 -- Loss : 5073.66064453125\n",
      "Epoch : 129/200 -- Loss : 4974.81005859375\n",
      "Epoch : 130/200 -- Loss : 5253.68798828125\n",
      "Epoch : 131/200 -- Loss : 4454.53173828125\n",
      "Epoch : 132/200 -- Loss : 4981.54296875\n",
      "Epoch : 133/200 -- Loss : 5041.93408203125\n",
      "Epoch : 134/200 -- Loss : 3841.54345703125\n",
      "Epoch : 135/200 -- Loss : 4397.83837890625\n",
      "Epoch : 136/200 -- Loss : 4298.07861328125\n",
      "Epoch : 137/200 -- Loss : 5768.99560546875\n",
      "Epoch : 138/200 -- Loss : 4531.77099609375\n",
      "Epoch : 139/200 -- Loss : 4861.6494140625\n",
      "Epoch : 140/200 -- Loss : 4908.666015625\n",
      "Epoch : 141/200 -- Loss : 4653.52978515625\n",
      "Epoch : 142/200 -- Loss : 3822.63671875\n",
      "Epoch : 143/200 -- Loss : 4562.72705078125\n",
      "Epoch : 144/200 -- Loss : 4233.1455078125\n",
      "Epoch : 145/200 -- Loss : 4658.13232421875\n",
      "Epoch : 146/200 -- Loss : 5210.943359375\n",
      "Epoch : 147/200 -- Loss : 4879.53466796875\n",
      "Epoch : 148/200 -- Loss : 4208.79052734375\n",
      "Epoch : 149/200 -- Loss : 4322.32470703125\n",
      "Epoch : 150/200 -- Loss : 3684.927734375\n",
      "Epoch : 151/200 -- Loss : 3876.846435546875\n",
      "Epoch : 152/200 -- Loss : 4587.5087890625\n",
      "Epoch : 153/200 -- Loss : 6444.18798828125\n",
      "Epoch : 154/200 -- Loss : 4672.02197265625\n",
      "Epoch : 155/200 -- Loss : 4417.15380859375\n",
      "Epoch : 156/200 -- Loss : 5713.00048828125\n",
      "Epoch : 157/200 -- Loss : 6655.412109375\n",
      "Epoch : 158/200 -- Loss : 4042.167724609375\n",
      "Epoch : 159/200 -- Loss : 4841.126953125\n",
      "Epoch : 160/200 -- Loss : 4535.03662109375\n",
      "Epoch : 161/200 -- Loss : 4428.880859375\n",
      "Epoch : 162/200 -- Loss : 4331.05419921875\n",
      "Epoch : 163/200 -- Loss : 4055.11083984375\n",
      "Epoch : 164/200 -- Loss : 3494.986328125\n",
      "Epoch : 165/200 -- Loss : 4352.900390625\n",
      "Epoch : 166/200 -- Loss : 3272.665283203125\n",
      "Epoch : 167/200 -- Loss : 4134.1474609375\n",
      "Epoch : 168/200 -- Loss : 5415.73193359375\n",
      "Epoch : 169/200 -- Loss : 4150.4697265625\n",
      "Epoch : 170/200 -- Loss : 3860.748046875\n",
      "Epoch : 171/200 -- Loss : 3391.836181640625\n",
      "Epoch : 172/200 -- Loss : 3595.44384765625\n",
      "Epoch : 173/200 -- Loss : 3748.838623046875\n",
      "Epoch : 174/200 -- Loss : 5536.41357421875\n",
      "Epoch : 175/200 -- Loss : 4556.1318359375\n",
      "Epoch : 176/200 -- Loss : 4839.05859375\n",
      "Epoch : 177/200 -- Loss : 4787.802734375\n",
      "Epoch : 178/200 -- Loss : 5379.0390625\n",
      "Epoch : 179/200 -- Loss : 4622.666015625\n",
      "Epoch : 180/200 -- Loss : 4373.880859375\n",
      "Epoch : 181/200 -- Loss : 5134.4951171875\n",
      "Epoch : 182/200 -- Loss : 6333.3828125\n",
      "Epoch : 183/200 -- Loss : 5664.51171875\n",
      "Epoch : 184/200 -- Loss : 4535.3203125\n",
      "Epoch : 185/200 -- Loss : 4812.2744140625\n",
      "Epoch : 186/200 -- Loss : 3524.9072265625\n",
      "Epoch : 187/200 -- Loss : 3992.367431640625\n",
      "Epoch : 188/200 -- Loss : 3973.85791015625\n",
      "Epoch : 189/200 -- Loss : 5728.4501953125\n",
      "Epoch : 190/200 -- Loss : 4980.35498046875\n",
      "Epoch : 191/200 -- Loss : 4755.98828125\n",
      "Epoch : 192/200 -- Loss : 5843.77783203125\n",
      "Epoch : 193/200 -- Loss : 5680.53369140625\n",
      "Epoch : 194/200 -- Loss : 5575.36181640625\n",
      "Epoch : 195/200 -- Loss : 3479.648681640625\n",
      "Epoch : 196/200 -- Loss : 3708.3720703125\n",
      "Epoch : 197/200 -- Loss : 3626.2373046875\n",
      "Epoch : 198/200 -- Loss : 4041.05517578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 199/200 -- Loss : 3410.563232421875\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "N = 1\n",
    "batch_size = 128\n",
    "learning_rate = 0.01\n",
    "teacher_forcing_prob = 0.75\n",
    "\n",
    "tensor_pairs = np.array(tensor_pairs)\n",
    "\n",
    "encoder = Encoder(input_lang.n_words, H)\n",
    "decoder = Decoder(output_lang.n_words, H)\n",
    "\n",
    "loss_criterion = nn.CrossEntropyLoss()\n",
    "encoder_optim = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "decoder_optim = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    idx = np.random.choice(np.arange(len(tensor_pairs)), batch_size, replace=False)\n",
    "    sample = tensor_pairs[idx]\n",
    "    \n",
    "    encoder_optim.zero_grad()\n",
    "    decoder_optim.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for pair in sample:\n",
    "        input_sentence = pair[0]\n",
    "        output_sentence = pair[1]\n",
    "        \n",
    "        # context becomes first hidden state of decoder\n",
    "        init_hidden = torch.zeros((1, N, H))\n",
    "        hidden_enc = encoder(torch.unsqueeze(input_sentence, axis=0), init_hidden)\n",
    "        \n",
    "        prev_word = torch.tensor(np.array([[[SOS_token]]]))\n",
    "        hidden_dec = hidden_enc\n",
    "        for word in output_sentence:\n",
    "            predicted_word_probs, hidden_dec = decoder(prev_word, hidden_dec)\n",
    "            \n",
    "            if random.random() < teacher_forcing_prob:\n",
    "                prev_word_value = word\n",
    "            else:\n",
    "                prev_word_value = torch.argmax(predicted_word_probs)\n",
    "            prev_word = torch.tensor(np.array([[[prev_word_value]]]))\n",
    "            \n",
    "            loss += loss_criterion(predicted_word_probs, word)\n",
    "            \n",
    "            if prev_word_value == EOS_token:\n",
    "                break\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optim.step()\n",
    "    decoder_optim.step()\n",
    "    \n",
    "    losses.append(loss.detach().numpy())\n",
    "    \n",
    "    print(f\"Epoch : {epoch}/{epochs} -- Loss : {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7606faa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(losses)), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d868f2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['elle', 'est', 'presque', 'aussi', 'grande', 'que', 'vous', '.', 'EOS']\n",
      "['she', 'is', 'almost', 'as', 'tall', 'as', 'you', '.', 'EOS']\n",
      "['she', 's', 'not', 'very', 'the', '.', 'EOS']\n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(tensor_pairs) # 10, 15 : i'm\n",
    "input_sentence = pair[0]\n",
    "output_sentence = pair[1]\n",
    "    \n",
    "# context becomes first hidden state of decoder\n",
    "init_hidden = torch.zeros((1, N, H))\n",
    "hidden_enc = encoder(torch.unsqueeze(input_sentence, axis=0), init_hidden)\n",
    "\n",
    "prev_word = torch.tensor(np.array([[[SOS_token]]]))\n",
    "hidden_dec = hidden_enc\n",
    "\n",
    "input_sentence_words = [input_lang.index2word[int(word_idx.numpy())] for word_idx in input_sentence]\n",
    "output_sentence_words = [output_lang.index2word[int(word_idx.numpy())] for word_idx in output_sentence]\n",
    "predicted_output_sentence = []\n",
    "\n",
    "prev_word_value = None\n",
    "\n",
    "while prev_word_value != EOS_token:\n",
    "    predicted_word_probs, hidden_dec = decoder(prev_word, hidden_dec)\n",
    "    prev_word_value = torch.argmax(predicted_word_probs) \n",
    "    prev_word = torch.tensor(np.array([[[prev_word_value]]]))\n",
    "\n",
    "    predicted_output_sentence.append(output_lang.index2word[int(prev_word_value.numpy())])\n",
    "                \n",
    "    if prev_word_value == EOS_token:\n",
    "        break\n",
    "\n",
    "print(input_sentence_words)\n",
    "print(output_sentence_words)\n",
    "print(predicted_output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663a0881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
